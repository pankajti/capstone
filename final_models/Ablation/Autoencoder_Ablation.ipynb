{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "max_words = 15000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "maxlen = 150\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/elmo/3\"\n",
    "embed = hub.load(\"/Users/shantanu/elmo_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (115864, 150)\n",
      "Shape of label tensor: (115864, 2)\n"
     ]
    }
   ],
   "source": [
    "root_dir = r'/Users/shantanu/Library/Mobile Documents/com~apple~CloudDocs/Capstone/Wikipedia Data'\n",
    "\n",
    "result_path = annot_file_path = os.path.join(root_dir , 'comments_with_grouped_annoptations.tsv')\n",
    "\n",
    "merged_comments = pd.read_table(result_path)\n",
    "merged_comments['recipient_attack'] = merged_comments['recipient_attack'].apply(lambda x : 1 if x> 1 else 0 )\n",
    "X_train = merged_comments['comment']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "y = merged_comments['recipient_attack']\n",
    "\n",
    "one_hot_train_labels = to_categorical(y)\n",
    "\n",
    "labels = np.asarray(one_hot_train_labels)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "labels = labels[indices]\n",
    "\n",
    "\n",
    "X_train, X_test_validate, y_train, y_test_validate = train_test_split(merged_comments.comment, merged_comments.recipient_attack,\n",
    "                                                    stratify = labels,\n",
    "                                                    test_size = 40,\n",
    "                                                    random_state = 123)\n",
    "\n",
    "DF_train = X_train.to_frame()\n",
    "DF_train['recipient_attack'] = y_train\n",
    "\n",
    "DF_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../tokenizer.pkl\",\"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model load \n",
    "\n",
    "model = load_model('../basic_lstm_with_auto_encoder.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "def preprocess_text(text_eval):\n",
    "    sequences = tokenizer.texts_to_sequences([text_eval])\n",
    "    data = pad_sequences(sequences, maxlen=maxlen)\n",
    "    return data\n",
    "\n",
    "\n",
    "def abalation(args):\n",
    "    ret = dict()\n",
    "    index, row = args\n",
    "    print(\"running for {}\".format(index))\n",
    "    text = row['comment'].translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens_without_sw = tokens  # [word for word in tokens if not word in stopwords.words()]\n",
    "    text = tf.convert_to_tensor([str(tokens_without_sw)])\n",
    "    out = embed.signatures['default'](text)['elmo']\n",
    "    pred_vals_array = np.empty((0, 2), float)\n",
    "    for i in range(len(tokens_without_sw) - 2):\n",
    "        text_eval = tokens_without_sw[i:i + 3]\n",
    "        a = preprocess_text(text_eval)\n",
    "        pred_vlaues = model.predict(a)\n",
    "        pred_vals_array = np.vstack((pred_vals_array, pred_vlaues))\n",
    "    elmo_vecs = update_mat(pred_vals_array, out, row.recipient_attack)\n",
    "    ret[row.recipient_attack] = elmo_vecs\n",
    "    return ret\n",
    "\n",
    "def update_mat(pred_vals_array, out, recipient_attack):\n",
    "    phrase_start_index = pred_vals_array[:, recipient_attack].argmax()\n",
    "    elmo_vecs_NAE = np.array(out[0][phrase_start_index:phrase_start_index + 3])\n",
    "    return elmo_vecs_NAE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment</th>\n",
       "      <th>recipient_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>6382</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Your not the only ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>97303</td>\n",
       "      <td>.NEWLINE_TOKENNEWLINE_TOKEN== Remove Legends =...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>64439</td>\n",
       "      <td>`::The differences in diagnosis rates is likel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>37389</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Eugen Vögler / Al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>10229</td>\n",
       "      <td>NEWLINE_TOKEN:Interesting, hadn't noticed that...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                            comment  \\\n",
       "574   6382  `NEWLINE_TOKENNEWLINE_TOKEN:Your not the only ...   \n",
       "575  97303  .NEWLINE_TOKENNEWLINE_TOKEN== Remove Legends =...   \n",
       "576  64439  `::The differences in diagnosis rates is likel...   \n",
       "577  37389  NEWLINE_TOKENNEWLINE_TOKEN== Eugen Vögler / Al...   \n",
       "578  10229  NEWLINE_TOKEN:Interesting, hadn't noticed that...   \n",
       "\n",
       "     recipient_attack  \n",
       "574                 1  \n",
       "575                 0  \n",
       "576                 0  \n",
       "577                 0  \n",
       "578                 1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sequential ():\n",
    "    for rec in DF_train.iterrows():\n",
    "        ret = abalation(rec)\n",
    "        print(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running for 7\n",
      "running for 8\n",
      "running for 9\n"
     ]
    }
   ],
   "source": [
    "a = list(map(abalation,DF_train.iloc[0:9999,:].iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: array([[-0.18450694,  0.0786566 , -0.00160237, ...,  0.09328601,\n",
       "           0.30909327, -0.7406552 ],\n",
       "         [-0.28309616,  0.40874362,  0.33764035, ...,  0.22987443,\n",
       "           0.63209915, -0.41705024],\n",
       "         [-0.44029447,  0.1612227 ,  0.28173673, ...,  0.00222512,\n",
       "           0.11175109, -0.46779114]], dtype=float32)},\n",
       " {1: array([[-0.23287071,  0.00908137,  0.09652573, ...,  0.11265226,\n",
       "           0.33093327, -0.287987  ],\n",
       "         [-0.6177983 , -0.10961051,  0.5007458 , ...,  0.06490551,\n",
       "           0.70277816,  0.01085995],\n",
       "         [-0.04294208,  0.17718947,  0.16293955, ...,  0.17081118,\n",
       "          -0.37689048, -0.578506  ]], dtype=float32)},\n",
       " {0: array([[-0.89535284, -0.2372038 ,  0.6088952 , ...,  0.08640732,\n",
       "           1.0694932 , -0.7675009 ],\n",
       "         [ 0.05310196, -0.12529181,  0.428167  , ..., -0.0774144 ,\n",
       "           0.05584092, -0.6399034 ],\n",
       "         [-0.4278134 ,  0.05618691,  0.29306653, ...,  0.08047161,\n",
       "           0.61658835, -0.04825191]], dtype=float32)}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.18450694, 0.0786566, -0.0016023666, 0.100...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[[-0.23287071, 0.009081371, 0.09652573, 0.2598...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.89535284, -0.2372038, 0.6088952, 0.818773...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [[-0.18450694, 0.0786566, -0.0016023666, 0.100...   \n",
       "1                                                NaN   \n",
       "2  [[-0.89535284, -0.2372038, 0.6088952, 0.818773...   \n",
       "\n",
       "                                                   1  \n",
       "0                                                NaN  \n",
       "1  [[-0.23287071, 0.009081371, 0.09652573, 0.2598...  \n",
       "2                                                NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[-0.3210175 ,  0.17366603,  0.5446634 , ...,  0.34253007,\n",
       "          0.75947845, -0.21353534],\n",
       "        [-0.49913216, -0.04212511, -0.05902478, ...,  0.63415277,\n",
       "          0.55470955, -0.35010707],\n",
       "        [-0.10557193, -0.10751615,  0.4985875 , ..., -0.08313151,\n",
       "          0.7551563 ,  0.00652687]], dtype=float32)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running for 0\n",
      "{0: array([[-0.3210175 ,  0.17366603,  0.5446634 , ...,  0.34253007,\n",
      "         0.75947845, -0.21353534],\n",
      "       [-0.49913216, -0.04212511, -0.05902478, ...,  0.63415277,\n",
      "         0.55470955, -0.35010707],\n",
      "       [-0.10557193, -0.10751615,  0.4985875 , ..., -0.08313151,\n",
      "         0.7551563 ,  0.00652687]], dtype=float32)}\n",
      "running for 1\n",
      "{0: array([[-0.41099688, -0.02160566,  0.04283985, ..., -0.13623561,\n",
      "         0.907256  , -0.12000874],\n",
      "       [-0.2678803 , -0.04774128,  0.4615938 , ...,  0.14850183,\n",
      "         1.5514276 , -0.02096853],\n",
      "       [-0.20045634,  0.19181986, -0.219108  , ..., -0.21944699,\n",
      "         0.6316541 , -0.43269682]], dtype=float32)}\n",
      "running for 2\n",
      "{0: array([[-0.22160067, -0.26873082,  0.38253418, ..., -0.02454223,\n",
      "         0.4395522 , -0.3907471 ],\n",
      "       [-0.5252863 ,  0.01354215,  0.5582873 , ...,  0.73088264,\n",
      "         0.3109154 , -0.47041026],\n",
      "       [-0.08268154, -0.27157763,  0.15044408, ...,  0.1597502 ,\n",
      "         0.7503923 , -0.54363966]], dtype=float32)}\n",
      "running for 3\n",
      "{0: array([[-0.5066886 , -0.20989797,  0.24283868, ..., -0.5826621 ,\n",
      "         0.63373214, -0.8422707 ],\n",
      "       [-0.34508252, -0.27363408,  0.15337738, ..., -0.41585833,\n",
      "        -0.50321174, -0.6099868 ],\n",
      "       [-0.4230107 , -0.07196267,  0.29201746, ...,  0.19631436,\n",
      "         0.1803668 , -0.18776357]], dtype=float32)}\n",
      "running for 4\n",
      "{1: array([[-0.1585824 , -0.02757615,  0.20612086, ..., -0.30972785,\n",
      "         1.4037695 , -0.7317809 ],\n",
      "       [-0.08364977, -0.26557326,  0.32893008, ..., -0.53946614,\n",
      "         1.0459208 , -0.99556935],\n",
      "       [-0.03302329,  0.12432002,  0.11898416, ..., -0.40524635,\n",
      "         1.0984411 , -0.49734417]], dtype=float32)}\n",
      "running for 5\n",
      "{0: array([[-0.77674687, -0.09934507,  0.01960599, ...,  0.6711242 ,\n",
      "         1.1599898 , -0.70931804],\n",
      "       [-0.7629124 , -0.2675877 ,  0.38143533, ..., -0.01343829,\n",
      "         0.5436435 , -0.7203203 ],\n",
      "       [-0.4978106 , -0.1966446 ,  0.32253677, ...,  0.143058  ,\n",
      "         0.29460707, -0.6881807 ]], dtype=float32)}\n",
      "running for 6\n",
      "{0: array([[-0.30138832, -0.28810102,  0.09536567, ..., -0.53445446,\n",
      "         1.5081868 , -0.8619269 ],\n",
      "       [-0.42975456, -0.2639969 ,  0.2764861 , ..., -0.3624466 ,\n",
      "         1.1521926 , -0.47358736],\n",
      "       [-0.31614602, -0.01089827,  0.50573283, ..., -0.17803895,\n",
      "         1.0472035 , -0.7796457 ]], dtype=float32)}\n",
      "running for 7\n",
      "{0: array([[-0.18450694,  0.0786566 , -0.00160237, ...,  0.09328601,\n",
      "         0.30909327, -0.7406552 ],\n",
      "       [-0.28309616,  0.40874362,  0.33764035, ...,  0.22987443,\n",
      "         0.63209915, -0.41705024],\n",
      "       [-0.44029447,  0.1612227 ,  0.28173673, ...,  0.00222512,\n",
      "         0.11175109, -0.46779114]], dtype=float32)}\n",
      "running for 8\n",
      "{1: array([[-0.23287071,  0.00908137,  0.09652573, ...,  0.11265226,\n",
      "         0.33093327, -0.287987  ],\n",
      "       [-0.6177983 , -0.10961051,  0.5007458 , ...,  0.06490551,\n",
      "         0.70277816,  0.01085995],\n",
      "       [-0.04294208,  0.17718947,  0.16293955, ...,  0.17081118,\n",
      "        -0.37689048, -0.578506  ]], dtype=float32)}\n",
      "running for 9\n",
      "{0: array([[-0.89535284, -0.2372038 ,  0.6088952 , ...,  0.08640732,\n",
      "         1.0694932 , -0.7675009 ],\n",
      "       [ 0.05310196, -0.12529181,  0.428167  , ..., -0.0774144 ,\n",
      "         0.05584092, -0.6399034 ],\n",
      "       [-0.4278134 ,  0.05618691,  0.29306653, ...,  0.08047161,\n",
      "         0.61658835, -0.04825191]], dtype=float32)}\n",
      "running for 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-8cfb01d705aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-154d7ccdbed1>\u001b[0m in \u001b[0;36mrun_sequential\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_sequential\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDF_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabalation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-1e5a20ddc836>\u001b[0m in \u001b[0;36mabalation\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtokens_without_sw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m  \u001b[0;31m# [word for word in tokens if not word in stopwords.words()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_without_sw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elmo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mpred_vals_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_without_sw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LEXACQ/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LEXACQ/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LEXACQ/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LEXACQ/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LEXACQ/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ret' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d1af5e1c2651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ret' is not defined"
     ]
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LEXACQ]",
   "language": "python",
   "name": "conda-env-LEXACQ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
