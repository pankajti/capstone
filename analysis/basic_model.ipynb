{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "from tensorflow import keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import os\n",
    "root_dir = r'/Users/pankaj/Library/Mobile Documents/com~apple~CloudDocs/Capstone/Wikipedia Data'\n",
    "\n",
    "\n",
    "result_path = annot_file_path = os.path.join(root_dir , 'comments_with_grouped_annoptations.tsv')\n",
    "\n",
    "merged_comments = pd.read_table(result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  rev_id                                            comment  \\\n",
      "0           0   37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...   \n",
      "1           1   44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...   \n",
      "2           2   49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...   \n",
      "3           3   89320   Next, maybe you could work on being less cond...   \n",
      "4           4   93890               This page will need disambiguation.    \n",
      "\n",
      "   year  logged_in       ns  sample  split  worker_id  quoting_attack  \\\n",
      "0  2002      False  article  random  train       9721             0.0   \n",
      "1  2002      False  article  random  train      20234             0.0   \n",
      "2  2002      False  article  random  train      26474             0.0   \n",
      "3  2002       True  article  random    dev      26738             0.0   \n",
      "4  2002       True  article  random  train       8010             0.0   \n",
      "\n",
      "   recipient_attack  third_party_attack  other_attack  attack  \n",
      "0               0.0                 0.0           0.0     0.0  \n",
      "1               0.0                 0.0           0.0     0.0  \n",
      "2               0.0                 0.0           0.0     0.0  \n",
      "3               2.0                 0.0           2.0     4.0  \n",
      "4               0.0                 0.0           0.0     0.0  \n"
     ]
    }
   ],
   "source": [
    "print (merged_comments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "115859    0\n",
       "115860    0\n",
       "115861    0\n",
       "115862    0\n",
       "115863    0\n",
       "Name: recipient_attack, Length: 115864, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_comments['recipient_attack'] = merged_comments['recipient_attack'].apply(lambda x : 1 if x> 1 else 0 )\n",
    "X_train = merged_comments['comment']\n",
    "y = merged_comments['recipient_attack']\n",
    "one_hot_train_labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115864,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         1\n",
       "4         0\n",
       "         ..\n",
       "115859    0\n",
       "115860    0\n",
       "115861    0\n",
       "115862    0\n",
       "115863    0\n",
       "Name: recipient_attack, Length: 115864, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_comments['recipient_attack'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO change model with proper word settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 187899 unique tokens.\n",
      "Shape of data tensor: (115864, 100)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training input  \n",
    "maxlen = 100\n",
    "training_samples = 20000\n",
    "validation_samples = 10000\n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "x_train = data[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (115864,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare labels \n",
    "labels = np.asarray(one_hot_train_labels)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "labels = labels[indices]\n",
    "y_train = labels[:training_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_collback = keras.callbacks.TensorBoard(log_dir = 'logs_classification', histogram_freq= 1)\n",
    "early_sp_cb= keras.callbacks.EarlyStopping(monitor='acc', min_delta=0.01, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks = [tb_collback, early_sp_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,018,113\n",
      "Trainable params: 18,113\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "embedding = Embedding(max_words, embedding_dim, input_length=maxlen)\n",
    "embedding.trainable = False\n",
    "model.add(embedding)\n",
    "model.add(LSTM(32))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 11s 531us/sample - loss: 0.5493 - acc: 0.7673 - val_loss: 0.5414 - val_acc: 0.7630\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 9s 447us/sample - loss: 0.5137 - acc: 0.7707 - val_loss: 0.5079 - val_acc: 0.7641\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "epochs=2,\n",
    "batch_size=256,\n",
    "validation_data=(x_val, y_val), callbacks= callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/Users/pankaj/anaconda/envs/nlp/bin:/Users/pankaj/anaconda/condabin:/Users/pankaj/anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/opt/X11/bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9a0c0a5632f21d59\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9a0c0a5632f21d59\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6011;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "PATH = os.getenv('PATH')\n",
    "%env PATH=/Users/pankaj/anaconda/envs/nlp/bin:$PATH\n",
    "    \n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
