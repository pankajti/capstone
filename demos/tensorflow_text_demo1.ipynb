{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-nightly in /Users/pankaj/anaconda/lib/python3.6/site-packages (2.2.0.dev20200317)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (0.33.4)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (3.11.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (1.18.1)\n",
      "Requirement already satisfied: tb-nightly<2.3.0a0,>=2.2.0a0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (2.2.0a20200317)\n",
      "Requirement already satisfied: tf-estimator-nightly in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (2.3.0.dev2020031701)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (1.27.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (1.11.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (0.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (1.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (3.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (2.10.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (1.4.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tf-nightly) (0.9.0)\n",
      "Requirement already satisfied: setuptools in /Users/pankaj/anaconda/lib/python3.6/site-packages (from protobuf>=3.8.0->tf-nightly) (41.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.11.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.15.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.6.11)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.6.0.post2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.2.6)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.23)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2019.11.28)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.6)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /Users/pankaj/anaconda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  !pip install tf-nightly\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='imdb_reviews',\n",
       "    version=1.0.0,\n",
       "    description='Large Movie Review Dataset.\n",
       "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
       "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
       "    features=FeaturesDict({\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "        'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
       "    }),\n",
       "    total_num_examples=100000,\n",
       "    splits={\n",
       "        'test': 25000,\n",
       "        'train': 25000,\n",
       "        'unsupervised': 50000,\n",
       "    },\n",
       "    supervised_keys=('text', 'label'),\n",
       "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
       "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
       "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
       "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
       "      month     = {June},\n",
       "      year      = {2011},\n",
       "      address   = {Portland, Oregon, USA},\n",
       "      publisher = {Association for Computational Linguistics},\n",
       "      pages     = {142--150},\n",
       "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = info.features['text'].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8185\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size: {}'.format(encoder.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded string is [4025, 222, 6307, 2327, 4043, 2120, 7975]\n",
      "The original string: \"Hello TensorFlow.\"\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Hello TensorFlow.'\n",
    "\n",
    "encoded_string = encoder.encode(sample_string)\n",
    "print('Encoded string is {}'.format(encoded_string))\n",
    "\n",
    "original_string = encoder.decode(encoded_string)\n",
    "print('The original string: \"{}\"'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4025 ----> Hell\n",
      "222 ----> o \n",
      "6307 ----> Ten\n",
      "2327 ----> sor\n",
      "4043 ----> Fl\n",
      "2120 ----> ow\n",
      "7975 ----> .\n"
     ]
    }
   ],
   "source": [
    "for index in encoded_string:\n",
    "  print('{} ----> {}'.format(index, encoder.decode([index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE )\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=1, embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "391/391 [==============================] - 651s 2s/step - loss: 0.6530 - accuracy: 0.5456 - val_loss: 0.4808 - val_accuracy: 0.7703\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 962s 2s/step - loss: 0.3554 - accuracy: 0.8488 - val_loss: 0.3458 - val_accuracy: 0.8505\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=2, batch_size =32,\n",
    "                    validation_data=test_dataset, \n",
    "                    validation_steps=30,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 112s 286ms/step - loss: 0.4732 - accuracy: 0.8552\n",
      "Test Loss: 0.473249226808548\n",
      "Test Accuracy: 0.8551599979400635\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_size(vec, size):\n",
    "  zeros = [0] * (size - len(vec))\n",
    "  vec.extend(zeros)\n",
    "  return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predict(sample_pred_text, pad):\n",
    "  encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
    "\n",
    "  if pad:\n",
    "    encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
    "  encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
    "  predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
    "\n",
    "  return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.7111266]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_pred_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=False)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06517394]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
    "                    'were out of this world. I would recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=True)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_graphs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-41d6f4a20f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_graphs' is not defined"
     ]
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
